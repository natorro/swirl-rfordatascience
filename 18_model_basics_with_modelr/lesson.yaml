- Class: meta
  Course: swirl-rfordatascience
  Lesson: 18_model_basics_with_modelr
  Author: your name goes here
  Type: Standard
  Organization: your organization's name goes here
  Version: 2.4.3

- Class: text
  Output: Ahora que ya tienes muchas herramientas podemos comenzar con modelación.

- Class: text
  Output: El objetivo de un modelo es proporcionar un resumen simple de un conjunto de datos, idealmente se encontrarán patrones generados por el fenómeno de interés y se ignorará el ruido.

- Class: text
  Output: Con ruido nos referimos a la variación aleatoria en la que no estamos interesados pues no nos ayudará a generar predicciones.

- Class: text
  Output: Durante el curso cubriremos únicamente modelos predictivos.

- Class: text
  Output: No veremos de manera formal o profunda la teoría matemática que está detras de los modelos. El curso está enfocado a darte herramientas para utilizar este tipo de modelos y entender mejor tus datos.

- Class: text
  Output: Te mostraremos como estos modelos son una buena herramienta para la exploración de datos.

- Class: text
  Output: Tradicionalmente los modelos se aplican en la inferencia o para confirmar hipótesis sobre los datos que  se tienen.

- Class: text
  Output: Hay dos puntos muy importantes que debes comprender para hacer una inferencia de la manera correcta.

- Class: text
  Output: Lo primero es que cada observación debe ser designada ya sea para exploración de los datos o confirmación de la hipótesis pero nunca para ambas.

- Class: text
  Output: Segundo, las observaciones se pueden utilizar repetidas veces para exploración, pero pueden usarse una sola vez para confirmación.


- Class: text
  Output: Lo que queremos decir con todo esto es que los datos que se utilizen para confirmación de hipótesis deben de ser independientes de los que sean usados para exploración.
  

- Class: text
  Output: Si no sigues estos pasos basicos, lo único que vas a lograr es un sobreajuste de tus datos y vas a modelar lo mismo que ya tienes por lo tanto tu modelo no será significativo a la hora de hacer una predicción y no servirá de nada tu análisis.

- Class: text
  Output: Sí quieres hacer una análisis serio para confirmación, tienes que dividir tus datos en tres grupos.


- Class: text
  Output: 60% será para training o exploración, donde podrás aplicarle distintos modelos y hacer visualizaciones.

- Class: text
  Output: 20% para el query set, donde compararas modelos o visualizaciones.

- Class: text
  Output: Finalmente 20% para test o confirmación, es para confirmar el modelo final.

- Class: text
  Output: Si haces todo esto podrás generar hipotesis candidatas y hacer distintas pruebas para estar más seguro del modelo final.

- Class: text
  Output: Conceptos básicos de modelos con modelr.

- Class: text
  Output: Para está lección será necesario que instales y mandes llamar la paquetería modelr.

- Class: text
  Output: también deberás llamar library(dplyr), library(purrr) & options(na.action = na.warn).

- Class: text
  Output: El primera es encontrar una familia de modelos que exprese el patrón que estás buscando pero de una forma genérica. 

- Class: text
  Output: Despues tienes que adecuar uno de estos modelos para que se aproxime a tus datos. Es importante entender que no por que se parezca implica que está bien o que sus predicciones serán correctas.

- Class: text
  Output: Veamos un modelo simple.


- Class: text
  Output: Vamos a utilizar la base de datos de diamonds contenida en ggplot2, también vamos a necesitar que tengas la paquetería de dplyr.


- Class: text
  Output: Extraeremos una subtabla que utilizaremos para hacer nuestras aproximaciones.


- Class: cmd_question
  Output: Corre el siguiente código dia <- head(diamonds, 100) %>% select(x, y) %>% as_tibble(dia)
  CorrectAnswer: dia <- head(diamonds, 100) %>% select(x, y) %>% as_tibble(dia)
  AnswerTests: omnitest(correctExpr='dia <- head(diamonds, 100) %>% select(x, y) %>% as_tibble(dia)')
  Hint: Usa el código que se te proporcionó.


- Class: cmd_question
  Output: Escribe dia para que veas el tibble que se creó.
  CorrectAnswer: dia
  AnswerTests: omnitest(correctExpr='dia')
  Hint: Escribe Día.




- Class: cmd_question
  Output: Ahora grafiquemos a df con la función ggplot y geom_point().
  CorrectAnswer: ggplot(dia, aes(x, y)) + geom_point()
  AnswerTests: omnitest(correctExpr='ggplot(dia, aes(x, y)) + geom_point()')
  Hint: Se grafica así ggplot(dia, aes(x, y)) + geom_point().

- Class: text
  Output: Como podrás ver se tiene un tendencia y una correlación entre los puntos de la gráfica.

- Class: text
  Output: Es claro que la relación entre los puntos se trata de un modelo lineal, ahora generaremos una familia de modelos líneales y los visualizaremos.

- Class: cmd_question
  Output: Utilizamos el siguiente código para generar a la familia linearm <- tibble(x1 = runif(300, -3, 6), x2 = runif(300, -3, 3))
  CorrectAnswer: linearm <- tibble(x1 = runif(300, -3, 6), x2 = runif(300, -3, 3))
  AnswerTests: omnitest(correctExpr='linearm <- tibble(x1 = runif(300, -3, 6), x2 = runif(300, -3, 3))')
  Hint: Escribe linearm <- tibble(x1 = runif(300, -3, 6), x2 = runif(300, -3, 3))

- Class: cmd_question
  Output: Graficamos con este código ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()
  CorrectAnswer: ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()
  AnswerTests: omnitest(correctExpr='ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()')
  Hint: Escribe ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()

- Class: text
  Output: En la gráfica anterior puedes ver 300 modelos líneales, pero la mayoría están my alejados de nuestros datos. Intuitivamente el mejor modelo es el que está más cerca de todos nuestros datos.

- Class: text
  Output: Dicho de una mejor manera si sumamos las distancias de cada punto a cada modelo, el modelo con la menor suma de distancias será el mejor.

- Class: text
  Output: Una manera fácil de empezar es midiendo la distancia vertical de cada punto al modelo.

- Class: text
  Output: Para obtener estas distancias debemos convertir nuestra familia de modelos en una función de r que tome como argumentos los parámetros y los datos y arroje las predicciones de los valores.

- Class: text
  Output: Como son modelos líneales, son de la forma y = a0 + a1 * x.

- Class: cmd_question
  Output: Creamos la función que convierte nuestra familia de modelos en una función de R. Escribe familym <- function(a, data) { a[1] + data$x * a[2]}
  CorrectAnswer: familym <- function(a, data) { a[1] + data$x * a[2]}
  AnswerTests: omnitest(correctExpr='familym <- function(a, data) { a[1] + data$x * a[2]}')
  Hint: EL código correcto es familym <- function(a, data) { a[1] + data$x * a[2]}

- Class: cmd_question
  Output: Ahora lo probamos con uno de los modelos que tenemos. Aplica la función con los siguientes argumentos familym(c(.25, 1.125), dia)
  CorrectAnswer: familym(c(.25, 1.125), dia)
  AnswerTests: omnitest(correctExpr='familym(c(.25, 1.125), dia)')
  Hint: Utiliza el código que se te proporciono. 

- Class: text
  Output: Ahora lo que queremos ver es la diferencia entre las prediciones y los valores reales. El problema es que tenemos 100 distancias y para hacer más eficiente la comparación entre modelos necesitamos un sólo valor.

- Class: text
  Output: En estadística una manera muy común de hacerlo es obteniendo el error promedio que se calcula haciendo la raiz cuadrada del promedio de las diferencias elevadas al cuadrado.

- Class: text
  Output: Para hacer eso se utilizaría el siguiente código.
  
- Class: text
  Output: distf <- function(modelo, data) {sqrt(mean((data$y - familym(modelo, data))^2))}
  
  
- Class: text
  Output: Seguido de esto aplicamos la función al tibble día con los siguientes parámetros. Podríamos ponerle cualquier par de parámetros que definan las función lineal pero procurá que tengan sentido para lo que quieres modelar.


- Class: text
  Output: distf(c(.25, 1.125), dia)


- Class: text
  Output: La cual nos arroja el valor de 0.7837071 que ya es mucho más fácil de comparar con otros modelos que los cien valores que teníamos en la tabla anterior.



- Class: text
  Output: Ahora podemos utilizar purrr para medir la distancia para todos los modelos que definimos previamente debemos modificar la función porque  la que teníamos anteriormente espera recibir el modelo como un vector de valores númericos de tamaño 2.

- Class: text
  Output: Creamos un función llamada dist1 para generalizar los modelos.

- Class: text
  Output: Con el siguiente código dist1 <- function(x, y) {distf(c(x, y), dia)}


- Class: text
  Output: Ahora añadiremos la segunda parte de la función en la que se realiza el mapeo de todos los modelos con lo que se obtendrá la distancia para cada modelo.

- Class: text
  Output: Con el siguiente código bestmodel <- linearm %>% mutate(dist = purrr::map2_dbl( x, y, dist1))
  

- Class: text
  Output: Se manda llamar para visualizar el resultado escribiendo bestmodel

- Class: figure
  Output: enter
  Figure: function1.R
  FigureType: new


- Class: figure
  Output: enter
  Figure: function2.R
  FigureType: new

- Class: cmd_question
  Output: Escribe bestmodel
  CorrectAnswer: bestmodel
  AnswerTests: omnitest(correctExpr='bestmodel')
  Hint: Escribe lo que se te pidió.

- Class: text
  Output: Mira la tabla que se generó con las distancia para cada par de puntos.

- Class: text
  Output: Ahora podemos visualizar que tal se adecuan los 10 mejores modelos a nuestros datos.

- Class: text
  Output: La cuestion es que queremos los mejores 10 modelos pero dada la cantidad de modelos no sería eficiente compararlos uno por uno.

- Class: text
  Output: Pero no te preocupes, para eso tenemos a r.

- Class: cmd_question
  Output: Utiliza el siguiente código para graficar los 10 mejores modelos según los datos que tenemos. ggplot(dia, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = x1, slope = x2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))
  CorrectAnswer: ggplot(dia, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = x1, slope = x2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))
  AnswerTests: omnitest(correctExpr='ggplot(dia, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = x1, slope = x2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))')
  Hint: Usa el código que se te proporcionó.





- Class: text
  Output: En la gráfica puedes ver los 10 modelos con la menor suma de distancias hacia los puntos, mientras más clara sea la línea menor es el promedio de las distancias.
