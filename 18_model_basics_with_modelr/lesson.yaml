- Class: meta
  Course: swirl-rfordatascience
  Lesson: 18_model_basics_with_modelr
  Author: your name goes here
  Type: Standard
  Organization: your organization's name goes here
  Version: 2.4.3

- Class: text
  Output: Ahora que ya tienes muchas herramientas podemos comenzar con modelación.

- Class: text
  Output: El objetivo de un modelo es proporcionar un resumen simple de un conjunto de datos, idealmente se encontrarán patrones generados por el fenómeno de interés y se ignorará el ruido.

- Class: text
  Output: Con ruido nos referimos a la variación aleatoria en la que no estamos interesados pues no nos ayudará a generar predicciones.

- Class: text
  Output: Durante el curso cubriremos únicamente modelos predictivos.

- Class: text
  Output: No veremos de manera formal o profunda la teoría matemática que está detras de los modelos. El curso está enfocado a darte herramientas para utilizar este tipo de modelos y entender mejor tus datos.

- Class: text
  Output: Te mostraremos como estos modelos son una buena herramienta para la exploración de datos.

- Class: text
  Output: Tradicionalmente los modelos se aplican en la inferencia o para confirmar hipótesis sobre los datos que  se tienen.

- Class: text
  Output: Hay dos puntos muy importantes que debes comprender para hacer una inferencia de la manera correcta.

- Class: text
  Output: Lo primero es que cada observación debe ser designada ya sea para exploración de los datos o confirmación de la hipótesis pero nunca para ambas.

- Class: text
  Output: Segundo, las observaciones se pueden utilizar repetidas veces para exploración, pero pueden usarse una sola vez para confirmación.


- Class: text
  Output: Lo que queremos decir con todo esto es que los datos que se utilizen para confirmación de hipótesis deben de ser independientes de los que sean usados para exploración.
  

- Class: text
  Output: Si no sigues estos pasos basicos, lo único que vas a lograr es un sobreajuste de tus datos y vas a modelar lo mismo que ya tienes por lo tanto tu modelo no será significativo a la hora de hacer una predicción y no servirá de nada tu análisis.

- Class: text
  Output: Sí quieres hacer una análisis serio para confirmación, tienes que dividir tus datos en tres grupos.


- Class: text
  Output: 60% será para training o exploración, donde podrás aplicarle distintos modelos y hacer visualizaciones.

- Class: text
  Output: 20% para el query set, donde compararas modelos o visualizaciones.

- Class: text
  Output: Finalmente 20% para test o confirmación, es para confirmar el modelo final.

- Class: text
  Output: Si haces todo esto podrás generar hipotesis candidatas y hacer distintas pruebas para estar más seguro del modelo final.

- Class: text
  Output: Conceptos básicos de modelos con modelr.

- Class: text
  Output: Para está lección será necesario que instales y mandes llamar la paquetería modelr.

- Class: text
  Output: también deberás llamar library(dplyr), library(purrr) & options(na.action = na.warn).

- Class: text
  Output: El primera es encontrar una familia de modelos que exprese el patrón que estás buscando pero de una forma genérica. 

- Class: text
  Output: Despues tienes que adecuar uno de estos modelos para que se aproxime a tus datos. Es importante entender que no por que se parezca implica que está bien o que sus predicciones serán correctas.

- Class: text
  Output: Veamos un modelo simple.


- Class: text
  Output: Vamos a utilizar la base de datos de diamonds contenida en ggplot2, también vamos a necesitar que tengas la paquetería de dplyr.


- Class: text
  Output: Extraeremos una subtabla que utilizaremos para hacer nuestras aproximaciones.


- Class: cmd_question
  Output: Corre el siguiente código dia <- head(diamonds, 100) %>% select(x, y) %>% as_tibble(dia)
  CorrectAnswer: dia <- head(diamonds, 100) %>% select(x, y) %>% as_tibble(dia)
  AnswerTests: omnitest(correctExpr='dia <- head(diamonds, 100) %>% select(x, y) %>% as_tibble(dia)')
  Hint: Usa el código que se te proporcionó.


- Class: cmd_question
  Output: Escribe dia para que veas el tibble que se creó.
  CorrectAnswer: dia
  AnswerTests: omnitest(correctExpr='dia')
  Hint: Escribe Día.




- Class: cmd_question
  Output: Ahora grafiquemos a df con la función ggplot y geom_point().
  CorrectAnswer: ggplot(dia, aes(x, y)) + geom_point()
  AnswerTests: omnitest(correctExpr='ggplot(dia, aes(x, y)) + geom_point()')
  Hint: Se grafica así ggplot(dia, aes(x, y)) + geom_point().

- Class: text
  Output: Como podrás ver se tiene un tendencia y una correlación entre los puntos de la gráfica.

- Class: text
  Output: Es claro que la relación entre los puntos se trata de un modelo lineal, ahora generaremos una familia de modelos líneales y los visualizaremos.

- Class: cmd_question
  Output: Utilizamos el siguiente código para generar a la familia linearm <- tibble(x1 = runif(3000, -3, 6), x2 = runif(3000, -3, 3))
  CorrectAnswer: linearm <- tibble(x1 = runif(3000, -3, 6), x2 = runif(3000, -3, 3))
  AnswerTests: omnitest(correctExpr='linearm <- tibble(x1 = runif(3000, -3, 6), x2 = runif(3000, -3, 3))')
  Hint: Escribe linearm <- tibble(x1 = runif(3000, -3, 6), x2 = runif(3000, -3, 3))

- Class: cmd_question
  Output: Graficamos con este código ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()
  CorrectAnswer: ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()
  AnswerTests: omnitest(correctExpr='ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()')
  Hint: Escribe ggplot(dia, aes(x, y)) + geom_abline(aes(intercept = x1, slope = x2), data = linearm, alpha = 1/3) + geom_point()

- Class: text
  Output: En la gráfica anterior puedes ver 3000 modelos líneales, pero la mayoría están my alejados de nuestros datos. Intuitivamente el mejor modelo es el que está más cerca de todos nuestros datos.

- Class: text
  Output: Dicho de una mejor manera si sumamos las distancias de cada punto a cada modelo, el modelo con la menor suma de distancias será el mejor.

- Class: text
  Output: Una manera fácil de empezar es midiendo la distancia vertical de cada punto al modelo.

- Class: text
  Output: Para obtener estas distancias debemos convertir nuestra familia de modelos en una función de r que tome como argumentos los parámetros y los datos y arroje las predicciones de los valores.

- Class: text
  Output: Como son modelos líneales, son de la forma y = a0 + a1 * x.

- Class: cmd_question
  Output: Creamos la función que convierte nuestra familia de modelos en una función de R. Escribe familym <- function(a, data) { a[1] + data$x * a[2]}
  CorrectAnswer: familym <- function(a, data) { a[1] + data$x * a[2]}
  AnswerTests: omnitest(correctExpr='familym <- function(a, data) { a[1] + data$x * a[2]}')
  Hint: EL código correcto es familym <- function(a, data) { a[1] + data$x * a[2]}

- Class: cmd_question
  Output: Ahora lo probamos con uno de los modelos que tenemos. Aplica la función con los siguientes argumentos familym(c(.25, 1.125), dia)
  CorrectAnswer: familym(c(.25, 1.125), dia)
  AnswerTests: omnitest(correctExpr='familym(c(.25, 1.125), dia)')
  Hint: Utiliza el código que se te proporciono. 

- Class: text
  Output: Ahora lo que queremos ver es la diferencia entre las prediciones y los valores reales. El problema es que tenemos 100 distancias y para hacer más eficiente la comparación entre modelos necesitamos un sólo valor.

- Class: text
  Output: En estadística una manera muy común de hacerlo es obteniendo el error promedio que se calcula haciendo la raiz cuadrada del promedio de las diferencias elevadas al cuadrado.

- Class: text
  Output: Para hacer eso se utilizaría el siguiente código.
  
- Class: text
  Output: distf <- function(modelo, data) {sqrt(mean((data$y - familym(modelo, data))^2))}
  
  
- Class: text
  Output: Seguido de esto aplicamos la función al tibble día con los siguientes parámetros. Podríamos ponerle cualquier par de parámetros que definan las función lineal pero procurá que tengan sentido para lo que quieres modelar.


- Class: text
  Output: distf(c(.25, 1.125), dia)


- Class: text
  Output: La cual nos arroja el valor de 0.7837071 que ya es mucho más fácil de comparar con otros modelos que los cien valores que teníamos en la tabla anterior.



- Class: text
  Output: Ahora podemos utilizar purrr para medir la distancia para todos los modelos que definimos previamente debemos modificar la función porque  la que teníamos anteriormente espera recibir el modelo como un vector de valores númericos de tamaño 2.

- Class: text
  Output: Creamos un función llamada dist1 para generalizar los modelos.

- Class: text
  Output: Con el siguiente código dist1 <- function(x, y) {distf(c(x, y), dia)}


- Class: text
  Output: Ahora añadiremos la segunda parte de la función en la que se realiza el mapeo de todos los modelos con lo que se obtendrá la distancia para cada modelo.

- Class: text
  Output: Con el siguiente código bestmodel <- linearm %>% mutate(dist = purrr::map2_dbl( x, y, dist1))
  

- Class: text
  Output: Se manda llamar para visualizar el resultado escribiendo bestmodel

- Class: figure
  Output: enter
  Figure: function1.R
  FigureType: new


- Class: figure
  Output: enter
  Figure: function2.R
  FigureType: new

- Class: cmd_question
  Output: Escribe bestmodel
  CorrectAnswer: bestmodel
  AnswerTests: omnitest(correctExpr='bestmodel')
  Hint: Escribe lo que se te pidió.

- Class: text
  Output: Mira la tabla que se generó con las distancia para cada par de puntos.

- Class: text
  Output: Ahora podemos visualizar que tal se adecuan los 10 mejores modelos a nuestros datos.

- Class: text
  Output: La cuestion es que queremos los mejores 10 modelos pero dada la cantidad de modelos no sería eficiente compararlos uno por uno.

- Class: text
  Output: Pero no te preocupes, para eso tenemos a r.

- Class: cmd_question
  Output: Utiliza el siguiente código para graficar los 10 mejores modelos según los datos que tenemos. ggplot(dia, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = x1, slope = x2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))
  CorrectAnswer: ggplot(dia, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = x1, slope = x2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))
  AnswerTests: omnitest(correctExpr='ggplot(dia, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = x1, slope = x2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))')
  Hint: Usa el código que se te proporcionó.





- Class: text
  Output: En la gráfica puedes ver los 10 modelos con la menor suma de distancias hacia los puntos, mientras más clara sea la línea menor es el promedio de las distancias.

- Class: text
  Output: Pero si lo analisas no tiene mucho sentido obtener tantos modelos, debe haber una forma más optima de obtener estos 10 modelos.

- Class: text
  Output: Pues si la hay, se le llama cuadrícula espacial de puntos.

- Class: text
  Output: La ventaja que te da esta cuadrícula es que te permite visualizar donde van a estar los mejores modelos.

- Class: text
  Output: Con el siguiente código la generas.

- Class: text
  Output: grid <- expand.grid(x1 = seq(3, 15, length = 20), x2 = seq(1.9, 3.9, length = 25)) %>% mutate(dist = purrr::map2_dbl(x1, x2, distf))

- Class: figure
  Output: enter
  Figure: function3.R
  FigureType: new


- Class: text
  Output: y con el siguiente se genera la gráfica de la red.

- Class: text
  Output: grid %>% ggplot(aes(x1, x2)) + geom_point(data = filter(grid, rank(dist) <= 10), size = 4, colour = "red") + geom_point(aes(color = -dist)) 

- Class: figure
  Output: grid
  Figure: function4.R
  FigureType: new


- Class: text
  Output: Como podrás apreciar se ve por dónde van a pasar los mejores modelos.
  

- Class: text
  Output: Ahora graficaremos los nuevos modelos con el siguiente código.

  
- Class: text
  Output: ggplot(sim1, aes(x, y)) + geom_point(size = 2, color = "grey30") + geom_abline(aes(intercept = x1, slope = x2, color = -dist), data = filter(grid, rank(dist) <= 100))


- Class: figure
  Output: .
  Figure: function5.R
  FigureType: new



- Class: text
  Output: Como podrás apreciar los modelos que se generan como los 10 mejores superan a los de la gráfica anterior.



- Class: text
  Output: Pasemos la siguiente tema.

- Class: text
  Output: Visualizando Modelos

- Class: text
  Output: Cuando trabajamos con modelos simples como en la lección anterior puedes darte cuenta de que patrones son capturados por el modelo estudiando la familia de modelos así como los coeficientes que se ajustan a los datos. 

- Class: text
  Output: En esta sección veremos un enfoque diferente.

- Class: text
  Output: Trataremos de entender el modelo a partir de sus predicciones y aunque suene extraño esto te ayudará a entender otros modelos predictivos.

- Class: text
  Output: Otra ventaja de los que vamos a ver es al analizar el modelo desde esta perspectiva es más fácil ver lo que el modelo no captura.

- Class: text
  Output: Predicciones

- Class: text
  Output: Para visualizar las predicciones comenzamos por generar un espacio cuadriculado que cubra la región en la que se encuentran nuestros datos.

- Class: text
  Output: Usaremos la función data_grid() que pertence a la paquetería de modelr.

- Class: cmd_question
  Output: Corre el siguiente código. cuadri <- dia %>% data_grid(x)
  CorrectAnswer: cuadri <- dia %>% data_grid(x)
  AnswerTests: omnitest(correctExpr='cuadri <- dia %>% data_grid(x)')
  Hint: Corre el código que se te proporcionó.

- Class: cmd_question
  Output: Ahora escribe cuadri para que veas lo que se generó.
  CorrectAnswer: cuadri
  AnswerTests: omnitest(correctExpr='cuadri')
  Hint: Corre el código que se te proporcionó.

- Class: text
  Output: Lo que hace el código que acabas de correr es que toma un data frame como primer argumento y para cada argumento subsecuente encuentra sus valores únicos y genera todas las combinaciones.

- Class: text
  Output: Ahora podemos agregar las predicciones con la función add_predictions() de modelr.

- Class: text
  Output: Esta función va a generar una nueva columna con las predicciones correspondientes.



- Class: cmd_question
  Output: Escribe cuadri <- cuadri %>% add_predictions(dia_mod)
  CorrectAnswer: cuadri <- cuadri %>% add_predictions(dia_mod)
  AnswerTests: omnitest(correctExpr='cuadri <- cuadri %>% add_predictions(dia_mod)')
  Hint: Usa el código que se te proporcionó.

- Class: text
  Output: El otro lado de las predicciones son los residuales,así como las predicciones te hablan de los patrones que capturo tu modelo, los residuales te hablan de lo que tu modelo se perdio. 

- Class: text
  Output: En palabras más simples son las distancia entre las predicciones de tus modelos y las observaciones.

- Class: text
  Output: Afortunadamente en R existe una función muy sencilla que sirve para agregar los residuales para cada estimación.

- Class: text
  Output: Funciona de manera similar a add_predictions() que vimos anteriormente.

- Class: text
  Output: Se usa add_residuals()

- Class: text
  Output: Es importante notar que al calcular los residuales debes pasar como primer argumento el dataset original seguido del estimado.

- Class: text
  Output: Nota -> El promedio de los residuales siempre debe ser igual a 0.

- Class: text
  Output: Ahora hablemos de modelos más generales en R.

- Class: text
  Output: La mayoría de las funciones de modelado en R usan conversiones estandar de formulas a fuciones.

- Class: text
  Output: Hemos visto conversiones simples como fue

- Class: text
  Output: y ~ x que se traduce a y = x1 + x2 * x

- Class: text
  Output: Para ver lo que hace R en realidad revisaremos la función model_matrix()

- Class: text
  Output: Como argumento recibe un data frame y un fórmula y devuelve un tibble que define la ecuación del modelo.

- Class: cmd_question
  Output: Escribe df <- tribble(~y, ~x1, ~x2, 3, 9, 5, 5, 4, 8)
  CorrectAnswer: df <- tribble(~y, ~x1, ~x2, 3, 9, 5, 5, 4, 8)
  AnswerTests: omnitest(correctExpr='df <- tribble(~y, ~x1, ~x2, 3, 9, 5, 5, 4, 8)')
  Hint: Escribe lo que se te indicó.

- Class: cmd_question
  Output: Escribe df para que veas lo que se generó.
  CorrectAnswer: df
  AnswerTests: omnitest(correctExpr='df')
  Hint: Escribe df.

- Class: text
  Output: Ahora vamos aplicar la función.

- Class: cmd_question
  Output: Escribe model_matrix(df, ~y, ~x1)
  CorrectAnswer: model_matrix(df, ~y, ~x1)
  AnswerTests: omnitest(correctExpr='model_matrix(df, ~y, ~x1)')
  Hint: Escribe model_matrix(df, ~y, ~x1).

- Class: text
  Output: R agrega la intercepción al modelo es simplemente por tener una columna que está llena de unos. 

- Class: text
  Output: R siempre agregará esta columna si no quieres eso, debes eliminarlo explícitamente con -1.

- Class: text
  Output: El código sería model_matrix(df, y ~ x1 - 1)

- Class: text
  Output: Variables Categóricas

- Class: text
  Output: Generar una función a partir de una fórmula puede ser sencillo cuando el predictor es continuo, pero las cosas se complican cuando es categórico.

- Class: text
  Output: Imagina que tienes una fórmula del tipo x ~ calificacion, donde calificacion puede ser aprobado, reprobado. 

- Class: text
  Output: No tendría sentido alguno pasar estos valores directamente a una fórmula del tipo y = x1 + x2*x.

- Class: text
  Output: Lo que tiene más sentido es asignar un valor a cada opción. Por ejemplo 1 aprobado y 0 reprobado.



- Class: text
  Output: Se vuelve 1 si está aprobado y cero si no.

- Class: cmd_question
  Output: Escribe el siguiente código. df <- tribble(~calificacion, ~respuesta, "aprobado", 1, "reprobado", 0, "aprobado", 1)
  CorrectAnswer: df <- tribble(~calificacion, ~respuesta, "aprobado", 1, "reprobado", 0, "aprobado", 1)
  AnswerTests: omnitest(correctExpr='df <- tribble(~calificacion, ~respuesta, "aprobado", 1, "reprobado", 0, "aprobado", 1)')
  Hint: Escribe lo que se te indicó.

- Class: cmd_question
  Output: Escribe df para que veas lo que se generó.
  CorrectAnswer: df
  AnswerTests: omnitest(correctExpr='df')
  Hint: Escribe df.

- Class: text
  Output: Ahora le aplicamos la función model_matrix()

- Class: cmd_question
  Output: Escribe model_matrix(df, respuesta ~ calificacion)
  CorrectAnswer: model_matrix(df, respuesta ~ calificacion)
  AnswerTests: omnitest(correctExpr='model_matrix(df, respuesta ~ calificacion)')
  Hint: Escribe model_matrix(df, respuesta ~ calificacion)

- Class: figure
  Output: enter.
  Figure: datasetpok.R
  FigureType: new

- Class: text
  Output: Ahora veamos nuestro dataset con el que haremos las siguientes pruebas de variables categóricas.

- Class: cmd_question
  Output: Teclea pokemon3
  CorrectAnswer: pokemon3
  AnswerTests: omnitest(correctExpr='pokemon3')
  Hint: Escribe pokemon3

- Class: text
  Output: En particula las columnas que usaremos serán categorical y Total.

- Class: text
  Output: Sí te fijas cada tipo1 representa un valor de categorical.

- Class: cmd_question
  Output: Escribe pokemon3 %>% select(categorical, Total)
  CorrectAnswer: pokemon3 %>% select(categorical, Total)
  AnswerTests: omnitest(correctExpr='pokemon3 %>% select(categorical, Total)')
  Hint: Escribe lo que se te indicó.

- Class: text
  Output: Ahora vamos a ajustar un modelo y generar predicciones.

- Class: cmd_question
  Output: Escribe mod2 <- lm(Total ~ categorical, data = pokemon3)
  CorrectAnswer: mod2 <- lm(Total ~ categorical, data = pokemon3)
  AnswerTests: omnitest(correctExpr='mod2 <- lm(Total ~ categorical, data = pokemon3)')
  Hint: Escribe lo que se te indicó.

- Class: cmd_question
  Output: Ahora  grid <- pokemon3 %>% data_grid(categorical) %>% add_predictions(mod2)
  CorrectAnswer: grid <- pokemon3 %>% data_grid(categorical) %>% add_predictions(mod2)
  AnswerTests: omnitest(correctExpr='grid <- pokemon3 %>% data_grid(categorical) %>% add_predictions(mod2)')
  Hint: Escribe lo que se te indicó.

- Class: cmd_question
  Output: Ahora  grid 
  CorrectAnswer: grid
  AnswerTests: omnitest(correctExpr='grid')
  Hint: Escribe lo que se te indicó.

- Class: text
  Output: Lo que sigue es graficar las predicciones con el siguiente código.

- Class: cmd_question
  Output: ggplot(pokemon3, aes(tipo1)) + geom_point(aes(y = Total)) + geom_point(data = grid, aes(y = pred), color = "red", size = 4)
  CorrectAnswer: ggplot(pokemon3, aes(tipo1)) + geom_point(aes(y = Total)) + geom_point(data = grid, aes(y = pred), color = "red", size = 4)
  AnswerTests: omnitest(correctExpr='ggplot(pokemon3, aes(tipo1)) + geom_point(aes(y = Total)) + geom_point(data = grid, aes(y = pred), color = "red", size = 4)')
  Hint: Usa el código que se te proporionó.

- Class: text
  Output: Lo siguiente que veremos es la interacción entre variables continuas y categóricas en un modelo.

- Class: text
  Output: Generaremos un data set para este ejemplo.

- Class: cmd_question
  Output: Escribe pokemon3 para que recuerdes lo que contiene ese dataset.
  CorrectAnswer: pokemon3
  AnswerTests: omnitest(correctExpr='pokemon3')
  Hint: Escribe pokemon3

- Class: text
  Output: Ahora utilizando funciones de dplyr generaremos el dataset pokemon4

- Class: cmd_question
  Output:  Escribe pokemon4 <- pokemon3 %>% select(Legendary, Attack, Total) %>% mutate(level_attack = ifelse(Attack < 55, 1, ifelse(Attack > 100, 3, 2))) %>% select(level_attack, Legendary, Total)
  CorrectAnswer: pokemon4 <- pokemon3 %>% select(Legendary, Attack, Total) %>% mutate(level_attack = ifelse(Attack < 55, 1, ifelse(Attack > 100, 3, 2))) %>% select(level_attack, Legendary, Total)
  AnswerTests: omnitest(correctExpr='pokemon4 <- pokemon3 %>% select(Legendary, Attack, Total) %>% mutate(level_attack = ifelse(Attack < 55, 1, ifelse(Attack > 100, 3, 2))) %>% select(level_attack, Legendary, Total)')
  Hint: Usa el código que se te proporcionó.

- Class: cmd_question
  Output:  Ahora escribe pokemon4 para que veas el resultado.
  CorrectAnswer: pokemon4
  AnswerTests: omnitest(correctExpr='pokemon4')
  Hint: Usa el código que se te proporcionó.

- Class: text
  Output: Seguido de esto lo gráficamos con el siguiente código.

- Class: cmd_question
  Output: Escribe ggplot(pokemon4, aes(level_attack, Total)) + geom_point(aes(color = Legendary))
  CorrectAnswer: ggplot(pokemon4, aes(level_attack, Total)) + geom_point(aes(color = Legendary))
  AnswerTests: omnitest(correctExpr='ggplot(pokemon4, aes(level_attack, Total)) + geom_point(aes(color = Legendary))')
  Hint: Usa el código que se te proporcionó.

- Class: text
  Output: Existen dos modelos que podrían ajustarse a estos datos.

- Class: text
  Output: Como primer modelo usaremos el siguiente código.

- Class: cmd_question
  Output: Escribe mod1 <- lm(Total ~ level_attack + Legendary, data = pokemon4)
  CorrectAnswer: mod1 <- lm(Total ~ level_attack + Legendary, data = pokemon4)
  AnswerTests: omnitest(correctExpr='mod1 <- lm(Total ~ level_attack + Legendary, data = pokemon4)')
  Hint: Usa el código que se te proporcionó.

- Class: cmd_question
  Output: Para el segundo escribe mod2 <- lm(Total ~ level_attack * Legendary, data = pokemon4)
  CorrectAnswer: mod2 <- lm(Total ~ level_attack * Legendary, data = pokemon4)
  AnswerTests: omnitest(correctExpr='mod2 <- lm(Total ~ level_attack * Legendary, data = pokemon4)')
  Hint: Usa el código que se te proporcionó.

- Class: text
  Output: Cuando sumas tus variables el modelo va a estimar su effecto de manera independiente, por el contrario cuando las multiplicas tanto la interacción entre ellas como su componente individual son incluidos en el modelo.

- Class: text
  Output: Para visualizar estos modelos vamos a utilizar dos funciones nuevas.

- Class: text
  Output: la primera es data_grid(), esta función encuentra todos los valores únicos de las variables que le metas y luego generá todas sus combinaciones.

- Class: text
  Output: La segunda función es gather_predictions() que añade la predicción para cada row. Esta función recibe los modelos como argumentos.

- Class: text
  Output: Vamos la ejercicio.

- Class: text
  Output: Para generar la red usamos el siguiente código.

- Class: cmd_question
  Output: Escribe grid <- pokemon4 %>% data_grid(level_attack, Legendary) %>% gather_predictions(mod1, mod2)
  CorrectAnswer: grid <- pokemon4 %>% data_grid(level_attack, Legendary) %>% gather_predictions(mod1, mod2)
  AnswerTests: omnitest(correctExpr='grid <- pokemon4 %>% data_grid(level_attack, Legendary) %>% gather_predictions(mod1, mod2)')
  Hint: Escribe lo que se te pidió.

- Class: cmd_question
  Output: Escribe grid para que veas lo que se generó.
  CorrectAnswer: grid
  AnswerTests: omnitest(correctExpr='grid')
  Hint: Escribe lo que se te pidió.

- Class: text
  Output: Ahora visualizemos los modelos.



- Class: cmd_question
  Output: Escribe ggplot(pokemon4, aes(level_attack, Total, color = Legendary)) + geom_point() + geom_line(data = grid, aes(y = pred)) + facet_wrap(~ model)
  CorrectAnswer: ggplot(pokemon4, aes(level_attack, Total, color = Legendary)) + geom_point() + geom_line(data = grid, aes(y = pred)) + facet_wrap(~ model)
  AnswerTests: omnitest(correctExpr='ggplot(pokemon4, aes(level_attack, Total, color = Legendary)) + geom_point() + geom_line(data = grid, aes(y = pred)) + facet_wrap(~ model)')
  Hint: Escribe lo que se te indicó.

- Class: text
  Output: Existen distinas formas de ver cual modelo es mejor para los datos.

- Class: text
  Output: Una forma de hacerlo es revisando los residuales.

- Class: cmd_question
  Output: Generamos los residuales con el siguiente código residuales <- pokemon4 %>% gather_residuals(mod1, mod2)
  CorrectAnswer: residuales <- pokemon4 %>% gather_residuals(mod1, mod2)
  AnswerTests: omnitest(correctExpr='residuales <- pokemon4 %>% gather_residuals(mod1, mod2)')
  Hint: Usa el código.

- Class: cmd_question
  Output: Ahora los visualizamos ggplot(residuales, aes(level_attack, resid, color = Legendary)) + geom_point() + facet_grid(model ~ Legendary)
  CorrectAnswer: ggplot(residuales, aes(level_attack, resid, color = Legendary)) + geom_point() + facet_grid(model ~ Legendary)
  AnswerTests: omnitest(correctExpr='ggplot(residuales, aes(level_attack, resid, color = Legendary)) + geom_point() + facet_grid(model ~ Legendary)')
  Hint: Usa el código.

- Class: text
  Output: Vemos que son muy similares. Aun que en los legendarios mod1 vemos que se perdió un poco más de información. Para hacerlo de manera más precisa se requiere tener cierto conocimiento matemático por lo que no lo veremos aquí.
