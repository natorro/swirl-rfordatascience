- Class: meta
  Course: swirl-rfordatascience
  Lesson: 18_model_basics_with_modelr
  Author: your name goes here
  Type: Standard
  Organization: your organization's name goes here
  Version: 2.4.3

- Class: text
  Output: Ahora que ya tienes muchas herramientas podemos comenzar con modelación.

- Class: text
  Output: El objetivo de un modelo es proporcionar un resumen simple de un conjunto de datos, idealmente se encontrarán patrones generados por el fenómeno de interés y se ignorará el ruido.

- Class: text
  Output: Con ruido nos referimos a la variación aleatoria en la que no estamos interesados pues no nos ayudará a generar predicciones.

- Class: text
  Output: Durante el curso cubriremos únicamente modelos predictivos.

- Class: text
  Output: No veremos de manera formal o profunda la teoría matemática que está detras de los modelos. El curso está enfocado a darte herramientas para utilizar este tipo de modelos y entender mejor tus datos.

- Class: text
  Output: Te mostraremos como estos modelos son una buena herramienta para la exploración de datos.

- Class: text
  Output: Tradicionalmente los modelos se aplican en la inferencia o para confirmar hipótesis sobre los datos que  se tienen.

- Class: text
  Output: Hay dos puntos muy importantes que debes comprender para hacer una inferencia de la manera correcta.

- Class: text
  Output: Lo primero es que cada observación debe ser designada ya sea para exploración de los datos o confirmación de la hipótesis pero nunca para ambas.

- Class: text
  Output: Segundo, las observaciones se pueden utilizar repetidas veces para exploración, pero pueden usarse una sola vez para confirmación.


- Class: text
  Output: Lo que queremos decir con todo esto es que los datos que se utilizen para confirmación de hipótesis deben de ser independientes de los que sean usados para exploración.
  

- Class: text
  Output: Si no sigues estos pasos basicos, lo único que vas a lograr es un sobreajuste de tus datos y vas a modelar lo mismo que ya tienes por lo tanto tu modelo no será significativo a la hora de hacer una predicción y no servirá de nada tu análisis.

- Class: text
  Output: Sí quieres hacer una análisis serio para confirmación, tienes que dividir tus datos en tres grupos.


- Class: text
  Output: 60% será para training o exploración, donde podrás aplicarle distintos modelos y hacer visualizaciones.

- Class: text
  Output: 20% para el query set, donde compararas modelos o visualizaciones.

- Class: text
  Output: Finalmente 20% para test o confirmación, es para confirmar el modelo final.

- Class: text
  Output: Si haces todo esto podrás generar hipotesis candidatas y hacer distintas pruebas para estar más seguro del modelo final.

- Class: text
  Output: Conceptos básicos de modelos con modelr.

- Class: text
  Output: Para está lección será necesario que instales y mandes llamar la paquetería modelr.

- Class: text
  Output: también deberás llamar library(tidyverse) & options(na.action = na.warn).

- Class: text
  Output: El primera es es encontrar una familia de modelos que exprese el patrón que estás buscando pero de una forma genérica. 

- Class: text
  Output: Despues tienes que adecuar uno de estos modelos para que se aproxime a tus datos. Es importante entender que no por que se parezca implica que está bien o que sus predicciones serán correctas.

- Class: text
  Output: Veamos un modelo simple.

- Class: cmd_question
  Output: Vamos a generar dos vectores. Escribe x = c(1, 2, 3, 5, 6).
  CorrectAnswer: x = c(1, 2, 3, 5, 6)
  AnswerTests: omnitest(correctExpr='x = c(1, 2, 3, 5, 6)')
  Hint: x = c(1, 2, 3, 5, 6)

- Class: cmd_question
  Output: Ahora escribe y = c(1, 3.5, 3, 5, 7).
  CorrectAnswer: y = c(1, 3.5, 3, 5, 7)
  AnswerTests: omnitest(correctExpr='y = c(1, 3.5, 3, 5, 7)')
  Hint: y = c(1, 3.5, 3, 5, 7)

- Class: cmd_question
  Output: Ahora crea un data frame con estos dos vectores y llámalo df.
  CorrectAnswer: df <- data.frame(x, y)
  AnswerTests: omnitest(correctExpr='df <- data.frame(x, y)')
  Hint: El código es df <- data.frame(x, y).

- Class: cmd_question
  Output: Ahora grafiquemos a df con la función ggplot y geom_point().
  CorrectAnswer: ggplot(df, aes(x, y)) + geom_point()
  AnswerTests: omnitest(correctExpr='ggplot(df, aes(x, y)) + geom_point()')
  Hint: Se grafica así ggplot(df, aes(x, y)) + geom_point().

- Class: text
  Output: Como podrás ver se tiene un tendencia y una correlación entre los puntos de la gráfica.

- Class: text
  Output: Pareciera que la relación entre los puntos se trata de un modelo lineal, ahora generaremos una familia de modelos líneales y los visualizaremos.

- Class: cmd_question
  Output: Utilizamos el siguiente código para generar a la familia linearm <- tibble(x1 = runif(300, -3, 6), y1 = runif(300, -3, 3))
  CorrectAnswer: linearm <- tibble(x1 = runif(300, -3, 6), y1 = runif(300, -3, 3))
  AnswerTests: omnitest(correctExpr='linearm <- tibble(x1 = runif(300, -3, 6), y1 = runif(300, -3, 3))')
  Hint: Escribe linearm <- tibble(x1 = runif(300, -3, 6), y1 = runif(300, -3, 3))

- Class: cmd_question
  Output: Graficamos con este código ggplot(df, aes(x, y)) + geom_abline(aes(intercept = x1, slope = y1), data = linearm, alpha = 1/3) + geom_point()
  CorrectAnswer: ggplot(df, aes(x, y)) + geom_abline(aes(intercept = x1, slope = y1), data = linearm, alpha = 1/3) + geom_point()
  AnswerTests: omnitest(correctExpr='ggplot(df, aes(x, y)) + geom_abline(aes(intercept = x1, slope = y1), data = linearm, alpha = 1/3) + geom_point()')
  Hint: Escribe ggplot(df, aes(x, y)) + geom_abline(aes(intercept = x1, slope = y1), data = linearm, alpha = 1/3) + geom_point()

- Class: text
  Output: En la gráfica anterior puedes ver 300 modelos líneales, pero la mayoría están my alejados de nuestros datos. Intuitivamente el mejor modelo es el que está más cerca de todos nuestros datos.

- Class: text
  Output: Dicho de una mejor manera si sumamos las distancias de cada punto a cada modelo, el modelo con la menor suma de distancias será el mejor.

- Class: text
  Output: Una manera fácil de empezar es midiendo la distancia vertical de cada punto al modelo.

- Class: text
  Output: Para obtener estas distancias debemos convertir nuestra familia de modelos en una función de r que tome como argumentos los parámetros y los datos y arroje las predicciones de los valores.

- Class: text
  Output: Como son modelos líneales, son de la forma y = a0 + a1 * x.

- Class: cmd_question
  Output: Creamos la función que convierte nuestra familia de modelos en una función de R. Escribe familym <- function(a, data) { a[1] + data$x * a[2]}
  CorrectAnswer: familym <- function(a, data) { a[1] + data$x * a[2]}
  AnswerTests: omnitest(correctExpr='familym <- function(a, data) { a[1] + data$x * a[2]}')
  Hint: EL código correcto es familym <- function(a, data) { a[1] + data$x * a[2]}

- Class: cmd_question
  Output: Ahora lo probamos con uno de los modelos que tenemos. Aplica la función con los siguientes argumentos familym(c(.25, 1.125), df)
  CorrectAnswer: familym(c(.25, 1.125), df)
  AnswerTests: omnitest(correctExpr='familym(c(.25, 1.125), df)')
  Hint: Utiliza el código que se te proporciono. 

- Class: text
  Output: Ahora lo que queremos ver es la diferencia entre las prediciones y los valores reales. El problema es que tenemos 5 distancias y para hacer más eficiente la comparación entre modelos necesitamos un sólo valor.

- Class: text
  Output: En estadística una manera muy común de hacerlo es obteniendo el error promedio que se calcula haciendo la raiz cuadrada del promedio de las diferencias elevadas al cuadrado.

- Class: cmd_question
  Output: Hacemos una función para hacer estos cálculos. Escribe distf <- function(modelo, data) {sqrt(mean((data$y - familym(modelo, data))^2))}
  CorrectAnswer: distf <- function(modelo, data) {sqrt(mean((data$y - familym(modelo, data))^2))}
  AnswerTests: omnitest(correctExpr='distf <- function(modelo, data) {sqrt(mean((data$y - familym(modelo, data))^2))}')
  Hint: Usa el código que se te proporcionó.

- Class: cmd_question
  Output: Ahora aplicamos la función que acabas de generar. Escribe distf(c(.25, 1.125), df)
  CorrectAnswer: distf(c(.25, 1.125), df)
  AnswerTests: omnitest(correctExpr='distf(c(.25, 1.125), df)')
  Hint: Usa el código que se te proporciono.





- Class: text
  Output: Ahora podemos utilizar purr para medir la distancia para todos los modelos que definimos previamente debemos modificar la función porque  la que teníamos anteriormente espera recibir el modelo como un vector de valores númericos de tamaño 2.

- Class: text
  Output: Creamos un función llamada dist1 para pata generalizar los modelos.

- Class: cmd_question
  Output: Utiliza el siguiente código para la primera parte de la función dist1 <- function(x, y) {distf(c(x, y), df)}
  CorrectAnswer: dist1 <- function(x, y) {distf(c(x, y), df)}
  AnswerTests: omnitest(correctExpr='dist1 <- function(x, y) {distf(c(x, y), df)}')
  Hint: Utiliza el código que se te proporciono.

- Class: text
  Output: Ahora añadiremos la segunda parte de la función en la que se realiza el mapeo de todos los modelos con lo que se obtendrá la distancia para cada modelo.

- Class: cmd_question
  Output: Utilice el siguiente código bestmodel <- linearm %>% mutate(dist = purrr::map2_dbl( x, y, dist1))
  CorrectAnswer: bestmodel <- linearm %>% mutate(dist = purrr::map2_dbl( x, y, dist1))
  AnswerTests: omnitest(correctExpr='bestmodel <- linearm %>% mutate(dist = purrr::map2_dbl( x, y, dist1))')
  Hint: Utiliza el código que se te proporciono.

- Class: cmd_question
  Output: Escribe bestmodel para poder visualizar la tabla que se generó.
  CorrectAnswer: bestmodel
  AnswerTests: omnitest(correctExpr='bestmodel')
  Hint: Escribe lo que se te indicó.

- Class: text
  Output: Ahora la cuestion es que queremos los mejores 10 modelos pero tenemos no dada la cantidad de modelos no sería eficiente compararlos uno por uno.

- Class: text
  Output: Pero no te preocupes, para eso tenemos a r.

- Class: cmd_question
  Output: Utiliza el siguiente código para graficar los 10 mejores modelos según los datos que tenemos. ggplot(dif1, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = a1, slope = a2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))
  CorrectAnswer: ggplot(dif1, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = a1, slope = a2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))
  AnswerTests: omnitest(correctExpr='ggplot(dif1, aes(x,y)) + geom_point(size = 2) + geom_abline(aes(intercept = a1, slope = a2, color = -dist), data = filter(bestmodel, rank(dist) <= 10))')
  Hint: Usa el código que se te proporcionó.

- Class: text
  Output: Ahora podemos visualizar que tal se adecuan los 10 mejores modelos a nuestros datos.
